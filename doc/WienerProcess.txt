The Gaussian probability distribution is given by $P(x_{1}...x_{N}|D) = \Big(\frac{1}{\sqrt{2D\pi(t_{n}-t_{n-1})}}\Big)^{N-1}
\exp{-\sum_{i=1}^{N-1}} \frac{x_{n} - x_{n-1}}{2D(t_{n}-t_{n-1})}$. Using Bayes theorem, the posterior probability 
distribution is written as follows:
    
\begin{equation}    
P(D|x_{1}...x_{N}) = \frac{P(x_{1}...x_{N}|D)\dot P(D)}{P(Data)} = \frac{
\Big(\frac{1}{\sqrt{2D\pi(t_{n}-t_{n-1})}}\Big)^{N-1}\exp{-\sum_{i=1}^{N-1}}\frac{\delta^{2}}{2D(\nabla_{t})}\dot P(D)}{P(Data)}(Eq.1)
\end{equation}

Taking logarithm of the above equation we get,

\begin{equation}  
\log P(D) = -\frac{N-1}{2}\log(2\pi D \nabla_{t})-\log D-\frac{\nabla^{2}}{2D\nabla_{t}} (Eq.2)
\end{equation}


Taking derivative with respect to D,

\begin{equation} 
\frac{\partial P}{\partial D} = -\frac{N-1}{2}\frac{1}{D}-\frac{1}{D}+\frac{\delta^{2}}{2D^{2}\nabla_{t}} (Eq.3)
\end{equation}
The best estimate of the diffusion values are given by the solution to the equation $\frac{\partial P}{\partial D} = 0$
\begin{equation}
\frac{1}{D}\frac{(N+1)}{2}+\frac{\delta^{2}}{2D^{2}\nabla_{t}} = 0 (Eq.4)
\end{equation}  

The best estimate or the most probable value of D is found as $\frac{\delta^{2}}{(N+1)\nabla_{t}}$. In this calculation, we worked with logarithm of P instead of only posterior pdf as the maximum occurs
at the same place as that of P. The time lag is set as one. The maximum at the peak gives the diffusion value of the given
data set and the corresponding normalisation condition will be $\int_{-\infty}^{\infty}P(x)dx = 1$.

import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pylab as pl
from __future__ import division

def logprob(D, dx2, dt, N):
    return -dx2/(2*D*dt) - np.log(D) -0.5*(N-1)*np.log(2*D*np.pi*(dt))
            
N = 1290
t = arange(N)                  # sampling times
dw = np.random.randn(N)        # Wiener increments
x = np.cumsum(dw)


dx2 = sum((x[1:] - x[:-1])**2)
dt = t[1] - t[0]


D = np.linspace(0.8,1.2, 1028)


plot(D, logprob(D, dx2, dt, N),'-',lw=1)


xlabel('D')
ylabel('P(D)')
grid('on')

print dx2/(N*dt)

# Measure of reliability or Error bar
d = (dx2/(N*dt)) / np.sqrt((N-2)+(dx2/dt))
print d
